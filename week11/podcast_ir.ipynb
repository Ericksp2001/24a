{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333ae546d607a744",
   "metadata": {},
   "source": [
    "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
    "\n",
    "## Objective:\n",
    "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a934919d95ac2de",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "### Step 1: Import Libraries\n",
    "Import necessary libraries for data handling, text processing, and machine learning.\n",
    "\n",
    "### Step 2: Load the Dataset\n",
    "\n",
    "Load the dataset of podcast transcripts.\n",
    "\n",
    "Find the dataset in: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript\n",
    "\n",
    "### Step 3: Text Preprocessing\n",
    "\n",
    "You know what to do ;)\n",
    "\n",
    "###  Step 4: Vector Space Representation - TF-IDF\n",
    "\n",
    "Create TF-IDF vector representations of the transcripts.\n",
    "\n",
    "### Step 5: Vector Space Representation - BERT\n",
    "\n",
    "Create BERT vector representations of the transcripts using a pre-trained BERT model.\n",
    "\n",
    "### Step 6: Query Processing\n",
    "\n",
    "Define a function to process the query and compute similarity scores using both TF-IDF and BERT embeddings.\n",
    "\n",
    "### Step 7: Retrieve and Compare Results\n",
    "\n",
    "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations.\n",
    "\n",
    "### Step 8: Test the IR System\n",
    "\n",
    "Test the system with a sample query.\n",
    "\n",
    "Retrieve and display the top results using both TF-IDF and BERT representations.\n",
    "\n",
    "### Step 9: Compare Results\n",
    "\n",
    "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
    "\n",
    "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "* Follow the steps outlined above to implement the IR system.\n",
    "* Run the provided code snippets to understand how each part of the system works.\n",
    "* Test the system with various queries to observe the results from both TF-IDF and BERT representations.\n",
    "* Compare and analyze the results. Discuss the pros and cons of each method.\n",
    "* Document your findings and any improvements you make to the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4691830",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "Import necessary libraries for data handling, text processing, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10bdec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf562318",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset\n",
    "\n",
    "Load the dataset of podcast transcripts.\n",
    "\n",
    "Find the dataset in: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cff6a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"data/podcastdata_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ef4bb",
   "metadata": {},
   "source": [
    "### Step 3: Text Preprocessing\n",
    "\n",
    "- Delete punctuation\n",
    "- Delete stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb17f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      As part of MIT course 6S099, Artificial Genera...\n",
      "1      As part of MIT course 6S099 on artificial gene...\n",
      "2      You've studied the human mind, cognition, lang...\n",
      "3      What difference between biological neural netw...\n",
      "4      The following is a conversation with Vladimir ...\n",
      "                             ...                        \n",
      "314    By the time he gets to 2045, we'll be able to ...\n",
      "315    there's a broader question here, right? As we ...\n",
      "316    Once this whole thing falls apart and we are c...\n",
      "317    you could be the seventh best player in the wh...\n",
      "318    turns out that if you train a planarian and th...\n",
      "Name: text, Length: 319, dtype: object\n"
     ]
    }
   ],
   "source": [
    "corpus = df[\"text\"]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7dc3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_nopunct = []\n",
    "for doc in corpus:\n",
    "    corpus_nopunct.append(doc.lower().translate(str.maketrans(\"\",\"\",string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1523c181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id            guest                    title  \\\n",
      "0   1      Max Tegmark                 Life 3.0   \n",
      "1   2    Christof Koch            Consciousness   \n",
      "2   3    Steven Pinker  AI in the Age of Reason   \n",
      "3   4    Yoshua Bengio            Deep Learning   \n",
      "4   5  Vladimir Vapnik     Statistical Learning   \n",
      "\n",
      "                                                text  \\\n",
      "0  As part of MIT course 6S099, Artificial Genera...   \n",
      "1  As part of MIT course 6S099 on artificial gene...   \n",
      "2  You've studied the human mind, cognition, lang...   \n",
      "3  What difference between biological neural netw...   \n",
      "4  The following is a conversation with Vladimir ...   \n",
      "\n",
      "                                        text_nopunct  \n",
      "0  as part of mit course 6s099 artificial general...  \n",
      "1  as part of mit course 6s099 on artificial gene...  \n",
      "2  youve studied the human mind cognition languag...  \n",
      "3  what difference between biological neural netw...  \n",
      "4  the following is a conversation with vladimir ...  \n"
     ]
    }
   ],
   "source": [
    "df[\"text_nopunct\"] = corpus_nopunct\n",
    "print(df.head())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopw = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e40b5dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "print(len(stopw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6e30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_nostw = []\n",
    "for doc in corpus_nopunct:\n",
    "    clean_doc = []\n",
    "    doc_array = doc.split(\" \")\n",
    "    for word in doc_array:\n",
    "        if word not in stopw:\n",
    "            clean_doc.append(word)\n",
    "    corpus_nostw.append(\" \".join(clean_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73c8e55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44733\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_nostw[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "754a042e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part mit course 6s099 artificial general intelligence ive gotten chance sit max tegmark professor mit hes physicist spent large part career studying mysteries cosmological universe hes also studied delved beneficial possibilities existential risks artificial intelligence amongst many things cofounder future life institute author two books highly recommend first mathematical universe second life 30 hes truly box thinker fun personality really enjoy talking youd like see videos future please subscribe also click little bell icon make sure dont miss videos also twitter linkedin agimitedu wanna watch lectures conversations like one better yet go read maxs book life 30 chapter seven goals favorite really philosophy engineering come together opens quote dostoevsky mystery human existence lies staying alive finding something live lastly believe every failure rewards us opportunity learn sense ive fortunate fail many new exciting ways conversation different ive learned something called radio frequency interference rfi look apparently music conversations local radio stations bleed audio youre recording way almost completely ruins audio exceptionally difficult sound source remove ive gotten opportunity learn avoid rfi future recording sessions ive also gotten opportunity learn use adobe audition izotope rx 6 noise audio repair course exceptionally difficult noise remove engineer im audio engineer neither anybody else group best nevertheless thank patience hope youre still able enjoy conversation think theres intelligent life universe lets open easy question minority view actually give public lectures often ask show hands thinks theres intelligent life somewhere else almost everyone put hands ask theyll like oh theres many galaxies theres gotta im numbers nerd right look carefully clear talk universe first dont mean space actually mean dont know throw universe want behind simply mean spherical region space light time reach us far 148 billion year 138 billion years since big bang theres space call universe thats access intelligent life thats gotten point building telescopes computers guess actually probability happening given planet number dont know know number cant super high theres billion earth like planets milky way galaxy alone many billions years older earth aside ufo believers isnt much evidence superduran civilization come thats famous fermi paradox right work numbers find clue probability getting life given planet could 10 minus 10 10 minus 20 10 minus two power 10 sort equally likely wanna really open minded translates equally likely nearest neighbor 10 16 meters away 10 17 meters away 10 18 time get much less 10 16 already pretty much know nothing else close get beyond 10 would discovered us yeah would discovered long ago theyre really close would probably noted engineering projects theyre beyond 10 26 meters thats already outside guess actually life thats gotten point building advanced tech think puts lot responsibility shoulders screw think people take granted okay us screw accidental nuclear war go extinct somehow theres sort star trek like situation life forms gonna come bail us doesnt matter much think theyre leveling us false sense security think much prudent say lets really grateful amazing opportunity weve make best case us physics perspective think intelligent life unique sort statistical view size universe basic matter universe difficult intelligent life come kind advanced tech building life implied statement really difficult create something like human species well think know going life life level tech theres sort two going beyond actually settling whole universe life theres major roadblock great filter sometimes called tough get either roadblock either behind us front us im hoping much behind us im super excited every time get new report nasa saying failed find life mars im like yes awesome suggests hard part maybe getting first ribosome low level kind stepping stone home free thats true future really limited imagination would much suckier turns level life kind dime dozen maybe theres problem like soon civilization gets advanced technology within hundred years get stupid fight poof would bummer yeah youve explored mysteries universe cosmological universe one thats sitting us today think youve also begun explore universe sort mystery mysterious universe mind intelligence intelligent life common thread interest way think space intelligence oh yeah teenager already fascinated biggest questions felt two biggest mysteries science universe universe quite natural spent quarter century career thinking lot one im indulging luxury research one cool feel time ripe trans greatly deepening understanding start exploring one yeah think lot people view intelligence something mysterious exist biological organisms like us therefore dismiss talk artificial general intelligence science fiction perspective physicist blob quarks electrons moving around certain pattern processing information certain ways also blob quarks electrons im smarter water bottle im made different kinds quarks im made quarks quarks exact kind theres secret sauce think pattern information processing means theres law physics saying cant create technology help us incredibly intelligent help us crack mysteries couldnt words think weve really seen tip intelligence iceberg far yeah perceptronium yeah coined amazing term hypothetical state matter sort thinking physics perspective kind matter help youre saying subjective experience emerge consciousness emerge think consciousness physics perspective good question think many people underestimated ability make progress convincing hopeless somehow missing ingredient need theres new consciousness particle whatever happen think missing anything interesting thing consciousness gives us amazing subjective experience colors sounds emotions rather something higher level patterns information processing thats like think idea perceptronium mean arbitrary physical system conscious terms particles information dont think hate carbon chauvinism attitude made carbon atoms smart conscious theres something information processing kind matter performs yeah see favorite equations describing various fundamental aspects world feel think one day maybe someone whos watching come equations information processing satisfy conscious im quite convinced big discovery made lets face know many things made information know information processing conscious conscious also know lot information processing conscious like information processing happening brain right conscious like 10 megabytes per second coming even visual system youre conscious heartbeat regulation things even ask like read says look oh know said youre aware computation actually happened consciousness like ceo got email end final answer makes difference think thats great science mystery actually studying little bit lab mit also think really urgent question answer starters mean youre emergency room doctor unresponsive patient coming wouldnt great addition ct scanner consciousness scanner could figure whether person actually locked syndrome actually comatose future imagine build robots machine really good conversations think likely happen wouldnt want know home helper robot actually experiencing anything like zombie mean would prefer would prefer would prefer actually unconscious dont feel guilty switching giving boring chores would prefer well certainly would prefer would prefer appearance consciousness question whether appearance consciousness different consciousness sort ask question think need understand consciousness solve hard problem consciousness order build something like agi system dont think think probably able build things even dont answer question want make sure happens good thing better solve first wonderful controversy youre raising basically three points view hard problem two different points view conclude hard problem consciousness bs one hand people like daniel dennett say consciousness bs consciousness thing intelligence theres difference anything acts conscious conscious like also lot people including many top ai researchers know say oh consciousness bullshit course machines never conscious theyre always going zombies never feel guilty treat theres third group people including giulio tononi example krzysztof koch number others would put also middle camp say actually information processing conscious lets find equation used determine think weve little bit lazy kind running away problem long time almost taboo even mention c word lot circles stop making excuses science question ways even test theory makes predictions coming back helper robot mean said youd want helper robot certainly act conscious treat like conversations stuff think wouldnt would feel would feel little bit creeped realized glossed tape recorder know zombie faking emotion would prefer actually experience would prefer actually experiencing anything feel dont feel guilty difficult question know like youre relationship say well love person said love back like asking well really love back saying love back dont really want actually love hard hard really know difference everything seeming like theres consciousness present theres intelligence present theres affection passion love actually im sure like ask question like make bit pointed mass general hospital right across river right yes suppose youre going medical procedure theyre like know anesthesia going going give muscle relaxants wont able move youre going feel excruciating pain whole surgery wont able anything going give drug erases memory would cool whats difference youre conscious theres behavioral change right right thats really thats really clear way put thats yeah feels like sense experiencing valuable quality actually able subjective experiences least case valuable think humans little bit bad track record also making self serving arguments entities arent conscious know people often say oh animals cant feel pain okay boil lobsters ask hurt didnt say anything paper saying lobsters feel pain boil theyre banning switzerland slaves often said oh dont mind dont maybe arent conscious women dont souls whatever im little bit nervous hear people take axiom machines cant experience ever think really fascinating science question lets research try figure makes difference unconscious intelligent behavior conscious intelligent behavior terms think boston dynamics human robot sort broom pushed around starts pushing consciousness question let ask think agi system like neuroscientists believe needs physical embodiment needs body something like body dont think mean conscious experience consciousness think helps lot physical embodiment learn kind things world important us humans sure dont think physical embodiment necessary youve learned experience think youre dreaming right eyes closed youre getting sensory input youre behaving moving way theres still experience right clearly experience see something cool dreams isnt coming eyes information processing brain experience right put another way ill say comes neuroscience reason want body physical something like physical know physical system want able preserve something order self could argue would need kind embodiment self want preserve well getting little bit anthropomorphic anthropomorphizing things maybe talking self preservation instincts mean evolved organisms right darwinian evolution endowed us evolved organism self preservation instinct didnt self preservation genes think quite convincingly answer question enough one kind look hood alphazero theres one kind neuron ridiculously simple mathematical thing like physics gas waves detailed nature molecule matter collective behavior somehow similarly higher level structure network matters 20 kinds neurons think brain complicated mess wasnt evolved intelligent involved also self assembling self repairing right evolutionarily attainable think pretty hunch going understand build agi fully understand brains work like understood build flying machines long able build mechanical bird yeah thats right youve given example exactly mechanical birds airplanes airplanes pretty good job flying without really mimicking bird flight even 100 years later see ted talk german mechanical bird heard mention check amazing even right still dont fly mechanical birds turned way came simpler better purposes think might thats one lesson another lesson paper first physicist thought fascinating theres close mathematical relationship actually artificial neural networks lot things weve studied physics go nerdy names like renormalization group equation hamiltonians yada yada yada look little closely first like well theres something crazy doesnt make sense know even want build super simple neural network tell apart cat pictures dog pictures right well think little bit convince must impossible one megapixel even pixel black white theres two power 1 million possible images way atoms universe right order one assign number probability dog arbitrary function images list numbers atoms universe clearly cant store hood gpu computer yet somehow works mean well means problems could try solve neural network almost impossible solve reasonably sized one showed paper fraction kind problems fraction problems could possibly pose actually care given laws physics also infinite testimony tiny little part amazingly theyre basically part yeah almost like world created mean kind come together yeah well could say maybe world created us modest interpretation world created us modest interpretation instead evolution endowed us neural networks precisely reason particular architecture opposed one laptop well adapted solving kind problems nature kept presenting ancestors makes sense brain first place able make predictions future sucky system could never solve wouldnt world think beautiful fact yeah also realize theres earlier work deeper networks good able show additional cool fact even incredibly simple problems like suppose give thousand numbers ask multiply together write lines code boom done trivial try neural network one single hidden layer youre going need two power thousand neurons multiply thousand numbers neurons atoms universe thats fascinating allow make deep network many layers need 4000 neurons perfectly feasible thats really interesting yeah another architecture type mean mentioned schrodingers equation thoughts quantum computing role kind computational unit creating intelligence system hollywood movies mention name dont want spoil way get agi building quantum computer word quantum sounds cool thats right first think dont need quantum computers build agi suspect brain quantum computer profound sense dont even wrote paper lot many years ago calculated called decoherence time long takes quantum computerness neurons gets erased random noise environment 10 minus 21 seconds cool would quantum computer head dont think fast hand cool things could quantum computers think well able soon get bigger ones might actually help machine learning even better brain example one moonshot learning much thing search youre trying train neural network get really learned something really well loss function bunch knobs turn represented bunch numbers youre trying tweak becomes good possible thing think landscape valley dimension landscape corresponds number change youre trying find minimum well known high dimensional landscape complicated things super hard find minimum quantum mechanics amazingly good like want know whats lowest energy state water possibly incredibly hard compute nature happily figure cool make cold put ball somewhere itll roll minimum happens metaphorically energy landscape quantum mechanics even uses clever tricks todays machine learning systems dont like youre trying find minimum get stuck little local minimum quantum mechanics actually tunnel barrier get unstuck thats really interesting yeah may example well one day use quantum computers help train neural networks better thats really interesting okay component kind learning process example yeah let ask sort wrapping little bit let return questions human nature love mentioned think mentioned sort helper robot could think also personal robots think way human beings fall love get connected possible achieve ai system human level ai intelligence system think would ever see kind connection know discussion solving complex goals kind human social connection think thats one goals peaks valleys raising sea levels well able achieve think thats something thats ultimately least short term relative goals achievable think possible mean recent theres wide range guesses know among ai researchers going get agi people know like friend rodney brooks says going hundreds years least many others think going happen much sooner recent polls maybe half ai researchers think going get agi within decades happens course think things possible terms whether happen think shouldnt spend much time asking think happen future sort pathetic passive bystanders know waiting future happen us hey ones creating future right proactive ask sort future would like happen going make like well prefer sort incredibly boring zombie like future theres mechanical things happening theres passion emotion experience maybe even would course much rather prefer things find value humanity subjective experience passion inspiration love know create future things happen things exist know think ultimately universe giving meaning us us giving meaning universe build advanced intelligence lets make sure build way meaning part lot people seriously study problem think different angles trouble majority cases think happen ones beneficial humanity yeah thoughts whats people know really dont like people terrified whats way people think way solve make better dont think panicking going help way going increase chances things going well either even situation real threat help everybody freaks course course think yeah course ways things go horribly wrong first important think thing problems risks also remember huge upsides get right right everything love society civilization product intelligence amplify intelligence machine intelligence anymore lose loved one told incurable disease things like course aspire motivator think reminding reason try solve problems trying avoid gloom trying something great terms risks think really important question ask today actually help make outcome good right dismissing risk one find quite funny often im discussion panels things people work companies always like oh nothing worry nothing worry nothing worry academics sometimes express concerns thats surprising think right upton sinclair quipped right hard make man believe something income depends believing frankly know lot people companies theyre concerned anyone else youre ceo company thats something want go record saying silly journalists gonna put picture terminator robot quote issues real way think issue basically real choice first gonna dismiss risks say well lets go ahead build machines everything better cheaper lets make obsolete fast possible could possibly go wrong thats one attitude opposite attitude think say heres incredible potential lets think kind future really really excited shared goals really aspire towards lets think really hard actually get start dont start thinking risks start thinking goals think obstacles want avoid often get students coming right office career advice always ask question want future say oh maybe ill cancer maybe ill get run truck yeah focus obstacles instead goals shes going end hypochondriac paranoid whereas comes fire eyes like want talk obstacles see circumvent thats think much much healthier attitude feel challenging come vision future unequivocally excited im talking vague terms like yeah lets cure cancer fine im talking kind society want create want mean human age ai age agi conversation broad inclusive conversation gradually start converging towards future direction least want steer towards right well much motivated constructively take obstacles think try wrap succinct way think agree already aspire build agi doesnt overpower us empowers us think many various ways whether thats side world autonomous vehicles im personally actually camp believes human level intelligence required achieve something like vehicles would actually something would enjoy using part thats one example certainly theres lot types robots medicine focusing coming obstacles coming ways go wrong solving one time build autonomous vehicle even could build one would drive fine without maybe things life would actually want thats right right like example think society whole things find meaningful doesnt mean stop machines better im gonna stop playing tennis day someone builds tennis robot beat people still playing chess even go yeah near term even people advocating basic income replace jobs government gonna willing hand cash people nothing one also seriously consider whether government also hire lot teachers nurses kind jobs people often find great fulfillment right get tired hearing politicians saying oh cant afford hiring teachers gonna maybe basic income serious research thought gives meaning lives jobs give much income right mm hmm think future roles wanna people continually feeling empowered machines think sort come russia soviet union think lot people 20th century going moon going space inspiring thing feel like universe mind ai understanding creating intelligence 21st century really surprising ive heard mention really surprising research funding side funded greatly could importantly politician side part public discourse except killer bots terminator kind view people yet think perhaps excited possible positive future build together politicians usually focus next election cycle right single important thing feel humans learned entire history science masters underestimation underestimated size cosmos realizing everything thought existed small part something grander right planet solar system galaxy clusters galaxies universe know future much potential ancestors could ever dreamt cosmos imagine earth completely devoid life except cambridge massachusetts wouldnt kind lame ever aspired stay cambridge massachusetts forever go extinct one week even though earth gonna continue longer sort attitude think cosmic scale life flourish earth four years billions years even tell move harms way sun gets hot much resources today maybe lot planets bacteria cow like life opportunity seems far tell largely dead like sahara desert yet opportunity help life flourish around billions years lets quit squabbling whether little border drawn one mile left right look skies realize hey incredible things yeah thats think really exciting others connected work elon musk hes literally going space really exploring universe wonderful exactly elon musk misunderstood right misconstrued kind pessimistic doomsayer reason cares much ai safety almost anyone else appreciates amazing opportunities well squander wipe earth going wipe next generation generations incredible opportunity thats would really waste ai people think would better without technology let mention dont improve technology question isnt whether humanity going go extinct question whether going get taken next big asteroid next super volcano something else dumb could easily prevent tech right want life flourish throughout cosmos ai key mentioned lot detail book right even many inspired sci fi writers feel totally underestimated opportunities space travel especially galaxies werent thinking possibility agi makes much easier right yeah goes view agi enables progress enables better life thats beautiful way put something strive max thank much thank time today awesome thank much thanks great day got cleaned gene pool right build artificial general intelligence mind space design much much larger specific subset minds evolve agi mind doesnt necessarily self preservation instinct also doesnt necessarily individualistic us like imagine could first also afraid death know suppose could back every five minutes airplane crash youre like shucks im gonna lose last five minutes experiences since last cloud backup dang know big deal could copy experiences minds easily like could easily silicon based right maybe would feel little bit like hive mind actually maybe dont think take granted agi sort competitive alpha male instincts hand know really interesting think people go far say course dont concerns either advanced ai instincts build anything want theres nice set arguments going back steve omohundro nick bostrom others pointing build machines normally build kind goal know win chess game drive car safely whatever soon put goal machine especially kind open ended goal machine intelligent itll break bunch sub goals one goals almost always self preservation breaks dies process gonna accomplish goal right like suppose build little little robot tell go store market get food make cook italian dinner know someone mugs tries break way robot incentive get destroyed defend run away otherwise gonna fail cooking dinner afraid death really wants complete dinner cooking goal self preservation instinct continue functional agent somehow similarly give kind ambitious goal agi likely wanna acquire resources better exactly sort sub goals might intended concerns agi safety come give goal seems completely harmless realize also trying things didnt want maybe smarter us fascinating let pause kind human centric way see fear death valuable motivator dont think think thats artifact evolution thats kind mind space evolution created sort almost obsessed self preservation kind genetic flow dont think thats necessary afraid death kind sub goal self preservation keep thing fundamentally sort finite thing like ends point interesting think necessary precisely intelligence also consciousness think really like finite death fear important answer agree whether necessary intelligence consciousness clear define two words cause lot really smart people define different ways panel ai experts couldnt agree define intelligence even define intelligence simply ability accomplish complex goals like broad definition dont want carbon chauvinist right case certainly doesnt require fear death would say alpha go alpha zero quite intelligent dont think alpha zero fear turned doesnt understand concept even similarly consciousness mean could certainly imagine simple kind experience certain plants kind experience dont think theyre afraid dying theres nothing anyway much wasnt much value seriously think ask conscious maybe would might call exciting life feel passion really appreciate things maybe somehow maybe perhaps help backdrop hey finite lets make lets live fullest knew going live forever think would change yeah mean perspective would incredibly boring life living forever sort loose subjective terms said something exciting something humans would understand think yeah seems finiteness important well good news based understand cosmology everything universe probably ultimately probably finite although big crunch big whats infinite expansion yeah could big chill big crunch big rip thats big snap death bubbles billion years away certainly vastly time ancestors thought still still pretty hard squeeze infinite number compute cycles even though loopholes might possible think know people like say live youre youre going die five years thats sort optimal maybe good assumption build civilization finite safe side right exactly mentioned defining intelligence ability solve complex goals would draw line would try define human level intelligence superhuman level intelligence consciousness part definition consciousness come definition think intelligence spectrum many different kinds goals goal good chess player good goal player good car driver good investor good poet et cetera intelligence nature isnt something measure one number overall goodness people better people better right machines much better us narrow tasks like multiplying large numbers fast memorizing large databases playing chess playing go soon driving cars theres still machine match human child general intelligence artificial general intelligence agi name course course definition quest build machine everything well old holy grail ai back inception sixties ever happens course think going biggest transition history life earth doesnt necessarily wait big impact machines better us knitting really big change doesnt come exactly moment theyre better us everything really big change comes first big changes start becoming better us jobs takes away much demand human labor really whopping change comes become better us ai research right right timescale ai research limited human research development cycle years typically know long take one release software iphone whatever next google replace 40000 engineers 40000 equivalent pieces software whatever theres reason years principle much faster timescale future progress ai science technology driven machines humans simple point gives right incredibly fun controversy whether intelligence explosion called singularity werner vinge called idea articulated ij good obviously way back fifties see alan turing others thought even earlier asked exactly would define human level intelligence yeah glib answer say something better us cognitive tasks better human cognitive tasks really interesting bar think goes little bit lower actually theyre better us ai programming general learning want get better us anything studying theyre better key word better towards kind spectrum complexity goals able accomplish another way thats certainly clear definition human love theres almost like sea thats rising things geographic show really nice way put theres peaks theres ocean level elevating solve problems kind take pause took bunch questions lot social networks bunch people asked sort slightly different direction creativity things perhaps arent peak human beings flawed perhaps better means contradiction flawed way let sort start easy first lot cool equations let ask whats favorite equation first know theyre like children like one shirt equation master key quantum mechanics micro world equation protect everything atoms molecules way right yeah okay quantum mechanics certainly beautiful mysterious formulation world id like sort ask example perhaps doesnt beauty physics mathematics abstract andrew wiles proved fermats last theorem saw recently kind caught eye little bit 358 years conjectured simple formulation everybody tried prove everybody failed heres guy comes along eventually proves fails prove proves 94 said like moment everything connected place interview said indescribably beautiful moment finally realize connecting piece two conjectures said indescribably beautiful simple elegant couldnt understand id missed stared disbelief 20 minutes day walked around department keep coming back desk looking see still still couldnt contain excited important moment working life nothing ever mean much particular moment kind made think would take think small levels maybe let ask moment like life idea like wow yes wouldnt mention breath andrew wiles ive certainly number aha moments realized something cool physics completely made head explode fact favorite discoveries made later later realized discovered earlier someone sometimes got quite famous late even publish doesnt diminish way emotional experience realize like wow yeah would take moment wow moment think takes intelligence system agi system ai system moment like thats tricky question actually two parts right one accomplish proof prove never write n plus b n equals three equal z n integers et cetera et cetera n bigger two thats simply question intelligence build machines intelligent think time get machine independently come level proofs probably quite close agi second question question consciousness likely machine actually experience opposed like zombie would expect sort emotional response anything akin human emotion accomplishes machine goal views somehow something positive sublime deeply meaningful would certainly hope future create machines peers even descendants would certainly hope sublime appreciation life way absolutely worst nightmare would point future distant future maybe cosmos teeming post biological life seemingly cool stuff maybe last humans time species eventually fizzles like well thats ok proud descendants look worst nightmare havent solved consciousness problem havent realized zombies theyre aware anything tape recorder kind experience whole thing become play empty benches would ultimate zombie apocalypse would much rather case beings really appreciate amazing picture would role creativity people ask creativity think intelligence certainly story told beginning book involved creating movies making money make lot money modern world music movies intelligent system may want get good thats necessarily mean creativity important complex goals sea rising something creative human centric thinking creativity somehow special relative intelligence hunch think creativity simply aspect intelligence careful human vanity tendency often want say soon machines something try diminish say oh thats real intelligence isnt creative thing ask write definition actually mean creative mean andrew wiles example dont often mean someone takes unexpected leap like taking 573 multiplying 224 step straightforward cookbook like rules right maybe make connection two things people never thought connected something like think aspect intelligence actually one important aspects maybe reason humans tend better traditional computers something comes naturally youre neural network youre traditional logic gate based computer machine physically connections activate activate activate bing hunch ever build machine could give task hey say hey realized want travel around world instead month teach agi course like ok ill everything would done improvises stuff would mind involve lot creativity yeah actually beautiful way put think try grasp definition intelligence everything dont understand build humans try find things machines dont maybe creativity one things one words use describe thats really interesting way put dont think need defensive dont think anything good comes saying well somehow special know contrary wise many examples history trying pretend somehow superior intelligent beings led pretty bad results right nazi germany said somehow superior people today still lot cruelty animals saying superior somehow cant feel pain slavery justified kind really weak arguments dont think actually go ahead build artificial general intelligence things better us dont think try found self worth sort bogus claims superiority terms intelligence think instead find calling meaning life experiences meaningful experiences even people smarter go faculty meeting talk something certainly realize oh boy old prize old prize old prize dont one make enjoy life less enjoy talking people less course contrary feel honored privileged get interact intelligent beings better lot stuff dont think theres reason cant approach intelligent machines thats really interesting people dont often think think theres going theres machines intelligent naturally think thats going beneficial type intelligence dont realize could like peers nobel prizes would fun talk might clever certain topics fun drinks well also another example relate doesnt terrible thing presence people even smarter us around two years old mean parents much intelligent us right worked ok goals aligned goals think really number one key issue solve value align value alignment problem exactly people see many hollywood movies lousy science fiction plot lines worry wrong thing right worry machine suddenly turning evil malice concern competence definition intelligent makes competent intelligent goal playing computer playing less intelligent one define intelligence ability accomplish goal winning going intelligent one wins human agi thats intelligent ways different goals guess whos going get way right reading particular rhinoceros species driven extinct years ago ellen bummer looking cute picture mommy rhinoceros child humans drive extinction wasnt evil rhino haters whole goals werent aligned rhinoceros didnt work well rhinoceros intelligent right think important ever build agi unleash anything make sure learns understand goals adopts goals retains goals cool interesting problem us human beings trying formulate values could think united states constitution way people sat time bunch white men good example say formulated goals country lot people agree goals actually held pretty well thats interesting formulation values failed miserably ways value alignment problem solution able put paper program human values difficult think important really give best difficult two separate reasons theres technical value alignment problem figuring make machines understand goals adopt retain theres separate part philosophical part whose values anyway since like great consensus planet values mechanism create aggregate decide ok whats good compromise second discussion cant left tech nerds like refuse talk agi gets built whos going actually making decision whose values going bunch dudes tech company necessarily representative humankind want entrust even uniquely qualified speak future human happiness theyre good programming ai id much rather really inclusive conversation think possible create beautiful vision includes diversity cultural diversity various perspectives discussing rights freedoms human dignity hard come consensus think certainly really important thing try think feasible think theres better way guarantee failure refuse talk refuse try also think really bad strategy say ok lets first discussion long time reach complete consensus well try load machine shouldnt let perfect enemy good instead start kindergarten ethics pretty much everybody agrees put machines even look anyone builds passenger aircraft wants never circumstances fly building mountain yet september 11 hijackers able even embarrassingly andreas lubitz depressed germanwings pilot flew passenger jet alps killing 100 people told autopilot told freaking computer change altitude 100 meters even though gps maps everything computer like ok take basic values problem dont agree problem weve lazy try put machines make sure airplanes computers refuse something like go safe mode maybe lock cockpit door go nearest airport theres much technology world well really becoming quite timely put sort basic values like even cars weve enough vehicle terrorism attacks people driven trucks vans pedestrians crazy idea hardwired car yeah lot theres always going people reason want harm others people dont technical expertise figure work around something like car wont helps lets start theres lot thats great point chasing perfect theres lot things world agrees yeah lets start lets start start well also get habit kind conversations okay else put discussions gradual process great also means describing things describing machine one thing conversations stephen wolfram im sure youre familiar stephen oh yeah know quite well works bunch things cellular automata simple computable things computation systems kind mentioned probably already within systems already something thats agi meaning like dont know cant talk give chance try least form question think interesting idea think intelligent systems dont know describe something cant communicate us know youre little bit work explainable ai trying get ai explain thoughts natural language processing kind communication ai explain something us explain something machines think differently two separate parts question one communication super interesting ill get sec whether already agi havent noticed right beg differ dont think theres anything cellular automaton anything internet whatever artificial general intelligence really exactly everything humans better think day happens happens soon notice well probably notice even big way second part though wait ask sorry beautiful way formulating consciousness information processing think intelligence information processing think entire universe particles systems roaming around information processing power dont think something power process information way human beings thats needs sort connected seems little bit philosophical perhaps theres something compelling idea power already focus able communicate well agree certain sense hardware processing power already universe think computer already right constantly computing water waves devolved water waves river charles move air molecules around seth lloyd pointed colleague even rigorous way think entire universe quantum computer pretty clear universe supports amazing processing power even within physics computer live right even build actual laptops stuff clearly power compute power nature opinion kind wasting boring stuff like simulating yet another ocean wave somewhere one even looking right sense life build computers rechanneling compute nature anyway things interesting yet another ocean wave lets something cool raw hardware power sure even computing whats going happen next five seconds water bottle takes ridiculous amount compute human computer water bottle mean water bottle agi agi means also able like ive written book done interview dont think communication problems dont really think although buddhists say watch water beauty theres depth beauty nature communicate communication also important though mean look part job teacher know intelligent professors even bit hard time communicating come brilliant ideas communicate somebody else also able simulate mind yes empathy build well enough understand model mind say things understand thats quite difficult thats today frustrating computer makes cancer diagnosis ask well saying surgery reply trained five terabytes data diagnosis boop boop beep beep doesnt really instill lot confidence right think lot work communication kind think youre little bit work explainable ai think promising avenues mostly sort alexa problem natural language processing able actually use human interpretable methods communication able talk system talk back fundamental problems solved think natural language processing obviously important also nerdy fundamental problems like take play chess course im russian speak russian yes speak russian excellent didnt know learn russian speak bad russian im autodidact bought book teach russian read lot difficult wow thats speak bad many languages know wow thats really impressive dont know wife calculation point play chess looked alphazero games actual games check mind blowing really beautiful ask go talk demis hassabis know others deepmind theyll ultimately able give big tables numbers matrices define neural network stare tables numbers till face turn blue youre gonna understand much made move even natural language processing tell human language oh five seven points two eight still gonna really help think theres whole spectrum fun challenges involved taking computation intelligent things transforming something equally good equally intelligent thats understandable think thats really valuable think put machines charge ever infrastructure world power grid trading stock market weapon systems absolutely crucial trust ais want trust really comes understanding fundamental way thats im working think gonna hope ensuring machines adopted goals theyre gonna retain kind trust think needs based things actually understand preferably even improve theorems even self driving car right someone tells trained tons data never crashed less reassuring someone actually proof maybe computer verified proof still says circumstances car gonna swerve oncoming traffic kind information helps build trust helps build alignment goals least awareness goals values aligned think even short term look know today right absolutely pathetic state cybersecurity three billion yahoo accounts cant pack almost every americans credit card happening ultimately happening software nobody fully understood worked thats bugs hadnt found right think ai used effectively offense hacking also used defense hopefully automating verifiability creating systems built different ways actually prove things important speaking software nobody understands works course bunch people ask paper thoughts deep cheap learning work well thats paper thoughts deep learning kind simplified models brains able successful perception work pattern recognition work alphazero clever things thoughts promise limitations piece great think number important insights important lessons always draw kinds successes one look human brain see complicated 10th 11 neurons different kinds neurons yada yada theres long debate whether fact dozens different kinds actually necessary intelligence\n"
     ]
    }
   ],
   "source": [
    "print(corpus_nostw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1fa3f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_stopw\"] = corpus_nostw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88679452",
   "metadata": {},
   "source": [
    "###  Step 4: Vector Space Representation - TF-IDF\n",
    "\n",
    "Create TF-IDF vector representations of the transcripts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18cf4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_mtx = vectorizer.fit_transform(df[\"text_stopw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3958d7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<319x49728 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 754029 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f5a6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Computer science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be42e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = vectorizer.transform([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7f567c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(tfidf_mtx,query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "499e95cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04507994],\n",
       "       [0.0727281 ],\n",
       "       [0.01451431],\n",
       "       [0.05681495],\n",
       "       [0.02340847],\n",
       "       [0.05354464],\n",
       "       [0.02846494],\n",
       "       [0.03237011],\n",
       "       [0.0169459 ],\n",
       "       [0.00614624],\n",
       "       [0.02421822],\n",
       "       [0.00593825],\n",
       "       [0.07372364],\n",
       "       [0.01775848],\n",
       "       [0.01775848],\n",
       "       [0.07208534],\n",
       "       [0.01616015],\n",
       "       [0.0054441 ],\n",
       "       [0.04327091],\n",
       "       [0.00503707],\n",
       "       [0.00667508],\n",
       "       [0.01006973],\n",
       "       [0.        ],\n",
       "       [0.02116541],\n",
       "       [0.10470165],\n",
       "       [0.01085762],\n",
       "       [0.06837741],\n",
       "       [0.01049236],\n",
       "       [0.00295929],\n",
       "       [0.00373142],\n",
       "       [0.00665419],\n",
       "       [0.01236771],\n",
       "       [0.02354847],\n",
       "       [0.        ],\n",
       "       [0.06939767],\n",
       "       [0.00935121],\n",
       "       [0.02700536],\n",
       "       [0.037525  ],\n",
       "       [0.07715644],\n",
       "       [0.03107165],\n",
       "       [0.07983962],\n",
       "       [0.08368498],\n",
       "       [0.02933174],\n",
       "       [0.03290134],\n",
       "       [0.02826904],\n",
       "       [0.04788385],\n",
       "       [0.01707148],\n",
       "       [0.01457681],\n",
       "       [0.02000268],\n",
       "       [0.05031207],\n",
       "       [0.06876471],\n",
       "       [0.01539101],\n",
       "       [0.02251366],\n",
       "       [0.07469056],\n",
       "       [0.02990532],\n",
       "       [0.        ],\n",
       "       [0.04266281],\n",
       "       [0.00873188],\n",
       "       [0.0381895 ],\n",
       "       [0.04427477],\n",
       "       [0.04785652],\n",
       "       [0.01908826],\n",
       "       [0.08766278],\n",
       "       [0.00685151],\n",
       "       [0.01699642],\n",
       "       [0.00664813],\n",
       "       [0.00748734],\n",
       "       [0.00494845],\n",
       "       [0.02003309],\n",
       "       [0.01463829],\n",
       "       [0.10809464],\n",
       "       [0.00952252],\n",
       "       [0.09779602],\n",
       "       [0.02752525],\n",
       "       [0.03825222],\n",
       "       [0.04623131],\n",
       "       [0.0638925 ],\n",
       "       [0.03628049],\n",
       "       [0.10164823],\n",
       "       [0.07035186],\n",
       "       [0.01913579],\n",
       "       [0.01454421],\n",
       "       [0.00334697],\n",
       "       [0.04500566],\n",
       "       [0.00498602],\n",
       "       [0.03200649],\n",
       "       [0.05229022],\n",
       "       [0.08856121],\n",
       "       [0.00457201],\n",
       "       [0.05198165],\n",
       "       [0.03093095],\n",
       "       [0.02024385],\n",
       "       [0.01442709],\n",
       "       [0.01915131],\n",
       "       [0.02421847],\n",
       "       [0.06511156],\n",
       "       [0.08019663],\n",
       "       [0.00732022],\n",
       "       [0.00668189],\n",
       "       [0.02150666],\n",
       "       [0.02629883],\n",
       "       [0.00728166],\n",
       "       [0.02886169],\n",
       "       [0.07875985],\n",
       "       [0.0480159 ],\n",
       "       [0.02833568],\n",
       "       [0.01457193],\n",
       "       [0.02154191],\n",
       "       [0.0318832 ],\n",
       "       [0.11099388],\n",
       "       [0.07100498],\n",
       "       [0.03846595],\n",
       "       [0.04709222],\n",
       "       [0.013886  ],\n",
       "       [0.03402037],\n",
       "       [0.01273718],\n",
       "       [0.00918951],\n",
       "       [0.01160225],\n",
       "       [0.0322608 ],\n",
       "       [0.01571395],\n",
       "       [0.00817097],\n",
       "       [0.00659069],\n",
       "       [0.00907202],\n",
       "       [0.04669305],\n",
       "       [0.00221089],\n",
       "       [0.04088074],\n",
       "       [0.        ],\n",
       "       [0.01153691],\n",
       "       [0.01257697],\n",
       "       [0.06038583],\n",
       "       [0.01609496],\n",
       "       [0.00707159],\n",
       "       [0.02144742],\n",
       "       [0.01010507],\n",
       "       [0.0579231 ],\n",
       "       [0.00231764],\n",
       "       [0.02725406],\n",
       "       [0.01909944],\n",
       "       [0.01484595],\n",
       "       [0.02635367],\n",
       "       [0.01910759],\n",
       "       [0.01745128],\n",
       "       [0.00081118],\n",
       "       [0.06677337],\n",
       "       [0.01802552],\n",
       "       [0.00433037],\n",
       "       [0.01877696],\n",
       "       [0.0526775 ],\n",
       "       [0.01686745],\n",
       "       [0.00237358],\n",
       "       [0.00896942],\n",
       "       [0.01988489],\n",
       "       [0.02269021],\n",
       "       [0.03928445],\n",
       "       [0.04532328],\n",
       "       [0.        ],\n",
       "       [0.02608682],\n",
       "       [0.01272406],\n",
       "       [0.00672453],\n",
       "       [0.01378004],\n",
       "       [0.00666738],\n",
       "       [0.03594974],\n",
       "       [0.01939415],\n",
       "       [0.03039039],\n",
       "       [0.0011198 ],\n",
       "       [0.03315971],\n",
       "       [0.00164728],\n",
       "       [0.0186177 ],\n",
       "       [0.00235947],\n",
       "       [0.00853828],\n",
       "       [0.00322383],\n",
       "       [0.00629709],\n",
       "       [0.01136332],\n",
       "       [0.01647527],\n",
       "       [0.00755798],\n",
       "       [0.00996459],\n",
       "       [0.02972815],\n",
       "       [0.00450268],\n",
       "       [0.00662963],\n",
       "       [0.00352466],\n",
       "       [0.00367141],\n",
       "       [0.03098229],\n",
       "       [0.03644637],\n",
       "       [0.01844379],\n",
       "       [0.00860918],\n",
       "       [0.01833624],\n",
       "       [0.02107748],\n",
       "       [0.01364411],\n",
       "       [0.01915665],\n",
       "       [0.01849403],\n",
       "       [0.01518795],\n",
       "       [0.02775337],\n",
       "       [0.0136715 ],\n",
       "       [0.02730734],\n",
       "       [0.03456172],\n",
       "       [0.00345311],\n",
       "       [0.00281071],\n",
       "       [0.01233889],\n",
       "       [0.00117778],\n",
       "       [0.        ],\n",
       "       [0.02321325],\n",
       "       [0.00552011],\n",
       "       [0.01014263],\n",
       "       [0.02533604],\n",
       "       [0.00259002],\n",
       "       [0.02404362],\n",
       "       [0.03034128],\n",
       "       [0.05381175],\n",
       "       [0.02302919],\n",
       "       [0.03451752],\n",
       "       [0.01991213],\n",
       "       [0.0465428 ],\n",
       "       [0.04937729],\n",
       "       [0.00968833],\n",
       "       [0.01701063],\n",
       "       [0.04719554],\n",
       "       [0.0331275 ],\n",
       "       [0.10061688],\n",
       "       [0.00750757],\n",
       "       [0.02906537],\n",
       "       [0.03717112],\n",
       "       [0.00050206],\n",
       "       [0.02676199],\n",
       "       [0.01568709],\n",
       "       [0.01878708],\n",
       "       [0.0138989 ],\n",
       "       [0.0046424 ],\n",
       "       [0.00416234],\n",
       "       [0.00222808],\n",
       "       [0.00802008],\n",
       "       [0.01947939],\n",
       "       [0.01032029],\n",
       "       [0.02605596],\n",
       "       [0.00453295],\n",
       "       [0.00079689],\n",
       "       [0.01372297],\n",
       "       [0.10554842],\n",
       "       [0.02901659],\n",
       "       [0.01472889],\n",
       "       [0.00707743],\n",
       "       [0.        ],\n",
       "       [0.00482239],\n",
       "       [0.00215977],\n",
       "       [0.00190038],\n",
       "       [0.02616541],\n",
       "       [0.02302874],\n",
       "       [0.00169007],\n",
       "       [0.03883336],\n",
       "       [0.01415213],\n",
       "       [0.00437692],\n",
       "       [0.01431829],\n",
       "       [0.00869654],\n",
       "       [0.03818735],\n",
       "       [0.00086006],\n",
       "       [0.00673949],\n",
       "       [0.04203354],\n",
       "       [0.02744625],\n",
       "       [0.00367687],\n",
       "       [0.00235699],\n",
       "       [0.04650626],\n",
       "       [0.05007884],\n",
       "       [0.02131568],\n",
       "       [0.00944061],\n",
       "       [0.        ],\n",
       "       [0.00276887],\n",
       "       [0.00570529],\n",
       "       [0.06125786],\n",
       "       [0.01444774],\n",
       "       [0.01722512],\n",
       "       [0.01054021],\n",
       "       [0.00714144],\n",
       "       [0.00806399],\n",
       "       [0.00227581],\n",
       "       [0.01214968],\n",
       "       [0.02029914],\n",
       "       [0.0009946 ],\n",
       "       [0.02026569],\n",
       "       [0.01469065],\n",
       "       [0.00987393],\n",
       "       [0.00362006],\n",
       "       [0.00610651],\n",
       "       [0.00535361],\n",
       "       [0.00050653],\n",
       "       [0.        ],\n",
       "       [0.00248318],\n",
       "       [0.02807863],\n",
       "       [0.03063591],\n",
       "       [0.01054367],\n",
       "       [0.00210224],\n",
       "       [0.00724051],\n",
       "       [0.02792312],\n",
       "       [0.00228663],\n",
       "       [0.04473269],\n",
       "       [0.00123992],\n",
       "       [0.00432103],\n",
       "       [0.03354831],\n",
       "       [0.00442528],\n",
       "       [0.00747256],\n",
       "       [0.04391917],\n",
       "       [0.01421825],\n",
       "       [0.01199059],\n",
       "       [0.01753573],\n",
       "       [0.01326593],\n",
       "       [0.0111606 ],\n",
       "       [0.00282586],\n",
       "       [0.00189071],\n",
       "       [0.01356744],\n",
       "       [0.0088438 ],\n",
       "       [0.00835176],\n",
       "       [0.        ],\n",
       "       [0.02400297],\n",
       "       [0.01686025],\n",
       "       [0.01266203],\n",
       "       [0.00404808],\n",
       "       [0.03615702],\n",
       "       [0.01863521],\n",
       "       [0.00094482],\n",
       "       [0.00339662],\n",
       "       [0.03031179]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d16cb0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sim</th>\n",
       "      <th>Episodio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045080</td>\n",
       "      <td>Life 3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.072728</td>\n",
       "      <td>Consciousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014514</td>\n",
       "      <td>AI in the Age of Reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056815</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023408</td>\n",
       "      <td>Statistical Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.036157</td>\n",
       "      <td>Singularity, Superintelligence, and Immortality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.018635</td>\n",
       "      <td>Emotion AI, Social Robots, and Self-Driving Cars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.000945</td>\n",
       "      <td>Comedy, MADtv, AI, Friendship, Madness, and Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.003397</td>\n",
       "      <td>Poker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.030312</td>\n",
       "      <td>Biology, Life, Aliens, Evolution, Embryogenesi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sim                                           Episodio\n",
       "0    0.045080                                           Life 3.0\n",
       "1    0.072728                                      Consciousness\n",
       "2    0.014514                            AI in the Age of Reason\n",
       "3    0.056815                                      Deep Learning\n",
       "4    0.023408                               Statistical Learning\n",
       "..        ...                                                ...\n",
       "314  0.036157    Singularity, Superintelligence, and Immortality\n",
       "315  0.018635   Emotion AI, Social Robots, and Self-Driving Cars\n",
       "316  0.000945  Comedy, MADtv, AI, Friendship, Madness, and Pr...\n",
       "317  0.003397                                              Poker\n",
       "318  0.030312  Biology, Life, Aliens, Evolution, Embryogenesi...\n",
       "\n",
       "[319 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities_df = pd.DataFrame(similarities, columns=[\"Sim\"])\n",
    "similarities_df[\"Episodio\"] = df[\"title\"]\n",
    "similarities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "570365d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve (query):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(tfidf_mtx,query_vector)\n",
    "    similarities_df = pd.DataFrame(similarities,columns=[\"Sim\"])\n",
    "    similarities_df[\"Episodio\"] = df[\"title\"]\n",
    "    return similarities_df.sort_values(by=\"Sim\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b89cba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sim</th>\n",
       "      <th>Episodio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.383218</td>\n",
       "      <td>Spotify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.100674</td>\n",
       "      <td>Legendary Music Producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.091897</td>\n",
       "      <td>The Existential Threat of Engineered Viruses a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.086500</td>\n",
       "      <td>The Next Generation of Big Ideas and Brave Minds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.068726</td>\n",
       "      <td>Virtual Reality, Social Media &amp; the Future of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Simulation and Superintelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Isaac Newton and the Philosophy of Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>OpenAI Codex, GPT-3, Robotics, and the Future ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Viruses and Vaccines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Stalin, Putin, and the Nature of Power</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sim                                           Episodio\n",
       "29   0.383218                                            Spotify\n",
       "272  0.100674                           Legendary Music Producer\n",
       "192  0.091897  The Existential Threat of Engineered Viruses a...\n",
       "157  0.086500   The Next Generation of Big Ideas and Brave Minds\n",
       "216  0.068726  Virtual Reality, Social Media & the Future of ...\n",
       "..        ...                                                ...\n",
       "83   0.000000                   Simulation and Superintelligence\n",
       "212  0.000000         Isaac Newton and the Philosophy of Science\n",
       "213  0.000000  OpenAI Codex, GPT-3, Robotics, and the Future ...\n",
       "214  0.000000                               Viruses and Vaccines\n",
       "63   0.000000             Stalin, Putin, and the Nature of Power\n",
       "\n",
       "[319 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve(\"music\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd5fac",
   "metadata": {},
   "source": [
    "### Step 5: Vector Space Representation - BERT\n",
    "\n",
    "Create BERT vector representations of the transcripts using a pre-trained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0db5780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "391d5505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indices</th>\n",
       "      <th>bert_embeding</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Life 3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>part mit course 6s099 artificial general intel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consciousness</td>\n",
       "      <td>0</td>\n",
       "      <td>part mit course 6s099 artificial general intel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI in the Age of Reason</td>\n",
       "      <td>0</td>\n",
       "      <td>youve studied human mind cognition language vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>0</td>\n",
       "      <td>difference biological neural networks artifici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Statistical Learning</td>\n",
       "      <td>0</td>\n",
       "      <td>following conversation vladimir vapnik hes co ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Singularity, Superintelligence, and Immortality</td>\n",
       "      <td>0</td>\n",
       "      <td>time gets 2045 well able multiply intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Emotion AI, Social Robots, and Self-Driving Cars</td>\n",
       "      <td>0</td>\n",
       "      <td>theres broader question right build socially e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Comedy, MADtv, AI, Friendship, Madness, and Pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>whole thing falls apart climbing kudzu vines s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Poker</td>\n",
       "      <td>0</td>\n",
       "      <td>could seventh best player whole world like lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Biology, Life, Aliens, Evolution, Embryogenesi...</td>\n",
       "      <td>0</td>\n",
       "      <td>turns train planarian cut heads tail regenerat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Indices  bert_embeding  \\\n",
       "0                                             Life 3.0              0   \n",
       "1                                        Consciousness              0   \n",
       "2                              AI in the Age of Reason              0   \n",
       "3                                        Deep Learning              0   \n",
       "4                                 Statistical Learning              0   \n",
       "..                                                 ...            ...   \n",
       "314    Singularity, Superintelligence, and Immortality              0   \n",
       "315   Emotion AI, Social Robots, and Self-Driving Cars              0   \n",
       "316  Comedy, MADtv, AI, Friendship, Madness, and Pr...              0   \n",
       "317                                              Poker              0   \n",
       "318  Biology, Life, Aliens, Evolution, Embryogenesi...              0   \n",
       "\n",
       "                                                  Text  \n",
       "0    part mit course 6s099 artificial general intel...  \n",
       "1    part mit course 6s099 artificial general intel...  \n",
       "2    youve studied human mind cognition language vi...  \n",
       "3    difference biological neural networks artifici...  \n",
       "4    following conversation vladimir vapnik hes co ...  \n",
       "..                                                 ...  \n",
       "314  time gets 2045 well able multiply intelligence...  \n",
       "315  theres broader question right build socially e...  \n",
       "316  whole thing falls apart climbing kudzu vines s...  \n",
       "317  could seventh best player whole world like lit...  \n",
       "318  turns train planarian cut heads tail regenerat...  \n",
       "\n",
       "[319 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert = pd.DataFrame(columns=[\"Indices\",\"bert_embeding\",\"Text\"])\n",
    "df_bert[\"Indices\"] = df[\"title\"]\n",
    "df_bert[\"Text\"] = df[\"text_stopw\"]\n",
    "df_bert[\"bert_embeding\"] =  np.zeros(319, dtype=int)\n",
    "df_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bc68931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
    "        outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :])  # Use [CLS] token representation\n",
    "    return np.array(embeddings).transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73f81a63",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_bert_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_nostw\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m res\n",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m, in \u001b[0;36mgenerate_bert_embeddings\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[0;32m      4\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :])  \u001b[38;5;66;03m# Use [CLS] token representation\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(embeddings)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:569\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    567\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[1;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1149\u001b[0m ):\n\u001b[1;32m-> 1150\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:437\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:1209\u001b[0m, in \u001b[0;36mTFBertModel.call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;129m@unpack_inputs\u001b[39m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(BERT_INPUTS_DOCSTRING\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size, sequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;129m@add_code_sample_docstrings\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     training: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1188\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[TFBaseModelOutputWithPoolingAndCrossAttentions, Tuple[tf\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;124;03m    encoder_hidden_states  (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03m        Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;124;03m        `past_key_values`). Set to `False` during training, `True` during generation\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1149\u001b[0m ):\n\u001b[1;32m-> 1150\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:437\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:969\u001b[0m, in \u001b[0;36mTFBertMainLayer.call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     head_mask \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers\n\u001b[1;32m--> 969\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    984\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(hidden_states\u001b[38;5;241m=\u001b[39msequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1149\u001b[0m ):\n\u001b[1;32m-> 1150\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:609\u001b[0m, in \u001b[0;36mTFBertEncoder.call\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    605\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[0;32m    607\u001b[0m past_key_value \u001b[38;5;241m=\u001b[39m past_key_values[i] \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 609\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1149\u001b[0m ):\n\u001b[1;32m-> 1150\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:502\u001b[0m, in \u001b[0;36mTFBertLayer.call\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    491\u001b[0m     hidden_states: tf\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[tf\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1149\u001b[0m ):\n\u001b[1;32m-> 1150\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:386\u001b[0m, in \u001b[0;36mTFBertAttention.call\u001b[1;34m(self, input_tensor, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    377\u001b[0m     input_tensor: tf\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m     training: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    385\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[tf\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 386\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_output(\n\u001b[0;32m    397\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mself_outputs[\u001b[38;5;241m0\u001b[39m], input_tensor\u001b[38;5;241m=\u001b[39minput_tensor, training\u001b[38;5;241m=\u001b[39mtraining\n\u001b[0;32m    398\u001b[0m     )\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;66;03m# add attentions (possibly with past_key_value) if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1149\u001b[0m ):\n\u001b[1;32m-> 1150\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:274\u001b[0m, in \u001b[0;36mTFBertSelfAttention.call\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(inputs\u001b[38;5;241m=\u001b[39mhidden_states), batch_size)\n\u001b[1;32m--> 274\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m, batch_size)\n\u001b[0;32m    276\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(mixed_query_layer, batch_size)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# if cross_attention save Tuple(tf.Tensor, tf.Tensor) of all cross attention key/value_states.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# Further calls to cross_attention layer can then reuse all cross-attention\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1149\u001b[0m ):\n\u001b[1;32m-> 1150\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:244\u001b[0m, in \u001b[0;36mDense.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    241\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(a\u001b[38;5;241m=\u001b[39minputs, b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# Broadcast kernel to inputs.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 244\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# Reshape the output back to the original ndim of the input.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:5185\u001b[0m, in \u001b[0;36mtensordot\u001b[1;34m(a, b, axes, name)\u001b[0m\n\u001b[0;32m   5183\u001b[0m b \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(b, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5184\u001b[0m a_axes, b_axes \u001b[38;5;241m=\u001b[39m _tensordot_axes(a, axes)\n\u001b[1;32m-> 5185\u001b[0m a_reshape, a_free_dims, a_free_dims_static \u001b[38;5;241m=\u001b[39m \u001b[43m_tensordot_reshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5186\u001b[0m b_reshape, b_free_dims, b_free_dims_static \u001b[38;5;241m=\u001b[39m _tensordot_reshape(\n\u001b[0;32m   5187\u001b[0m     b, b_axes, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5188\u001b[0m ab_matmul \u001b[38;5;241m=\u001b[39m matmul(a_reshape, b_reshape)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:5111\u001b[0m, in \u001b[0;36mtensordot.<locals>._tensordot_reshape\u001b[1;34m(a, axes, flipped)\u001b[0m\n\u001b[0;32m   5109\u001b[0m   a_trans \u001b[38;5;241m=\u001b[39m a\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a_trans\u001b[38;5;241m.\u001b[39mget_shape()\u001b[38;5;241m.\u001b[39mas_list() \u001b[38;5;241m!=\u001b[39m new_shape:\n\u001b[1;32m-> 5111\u001b[0m   reshaped_a \u001b[38;5;241m=\u001b[39m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5113\u001b[0m   reshaped_a \u001b[38;5;241m=\u001b[39m a_trans\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:198\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanip.reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     63\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(tensor, shape, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m   shape_util\u001b[38;5;241m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[0;32m    200\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10635\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m  10633\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m  10634\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m> 10635\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreshape_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10636\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10637\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[0;32m  10638\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10660\u001b[0m, in \u001b[0;36mreshape_eager_fallback\u001b[1;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[0;32m  10658\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [tensor, shape]\n\u001b[0;32m  10659\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_T, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_Tshape)\n\u001b[1;32m> 10660\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10661\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[0;32m  10663\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[0;32m  10664\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[1;32mc:\\Users\\erick\\Escritorio\\RI\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = generate_bert_embeddings(corpus_nostw[0])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fb6e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "with Pool(processes=8) as pool:\n",
    "    res = pool.map(generate_bert_embeddings,corpus_nostw[0])\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dfb620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_bert(query):\n",
    "    query_bert = ([query])[0]\n",
    "    similarities_bert = cosine_similarity(query_bert.reshape(1, -1), bert_embeddings)\n",
    "    similarities_df = pd.DataFrame(similarities_bert[:, 0], columns=[\"Sim\"])\n",
    "    similarities_df[\"Episodio\"] = df[\"title\"]\n",
    "    return similarities_df.sort_values(by=\"Sim\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e25bc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sim</th>\n",
       "      <th>Episodio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.647408</td>\n",
       "      <td>Life 3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sim  Episodio\n",
       "0  0.647408  Life 3.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_bert(\"Computer Science\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
