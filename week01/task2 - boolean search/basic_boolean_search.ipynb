{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Basic Boolean Search in Documents\n",
    "\n",
    "## Objective\n",
    "Expand the simple term search functionality to include Boolean search capabilities. This will allow users to perform more complex queries by combining multiple search terms using Boolean operators.\n",
    "\n",
    "## Problem Description\n",
    "You must enhance the existing search engine from the previous exercise to support Boolean operators: AND, OR, and NOT. This will enable the retrieval of documents based on the logical relationships between multiple terms."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Requirements\n",
    "\n",
    "### Step 1: Update Data Preparation\n",
    "Ensure that the documents are still loaded and preprocessed from the previous task. The data should be clean and ready for advanced querying."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\erick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\erick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Descargar el corpus de stopwords y punkt si no está disponible\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 2: Create an Inverted Index\n",
    "\n",
    "Create an inverted index from the documents. This index maps each word to the set of document IDs in which that word appears. This facilitates word lookup in the search process."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T00:34:40.219312Z",
     "start_time": "2024-05-01T00:34:40.209307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_inverted_index(directory):\n",
    "    index = {}\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files[:100]:  # Take only the first 100 files\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read().lower()  # Convert to lowercase\n",
    "                tokens = word_tokenize(content)\n",
    "                tokens = [stemmer.stem(token) for token in tokens if token not in stopwords.words('english') and token not in string.punctuation]\n",
    "                for word in tokens:\n",
    "                    if word in index:\n",
    "                        index[word].append(file_path)\n",
    "                    else:\n",
    "                        index[word] = [file_path]\n",
    "    return index"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T01:32:55.390506Z",
     "start_time": "2024-05-01T00:34:45.442315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directory where the documents are located\n",
    "directory = \"../../data\"\n",
    "\n",
    "inverted_index = create_inverted_index(directory)\n",
    "print(\"Inverted index created.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted index created.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T01:34:23.290549Z",
     "start_time": "2024-05-01T01:34:16.918372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the inverted index into a dataframe\n",
    "df_index = pd.DataFrame([(word, files) for word, files in inverted_index.items()], columns=['Word', 'Files'])\n",
    "\n",
    "# Save the inverted index as a CSV file\n",
    "df_index.to_csv('inverted_index.csv', index=False)\n",
    "\n",
    "print(\"Inverted index saved as 'inverted_index.csv'.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted index saved as 'inverted_index.csv'.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 3: Query Processing\n",
    "- **Parse the Query**: Implement a function to parse the input query to identify the terms and operators.\n",
    "- **Search Documents**: Based on the parsed query, implement the logic to retrieve and rank the documents according to the Boolean expressions."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T01:59:18.015138Z",
     "start_time": "2024-05-01T01:59:14.661824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cargar el archivo CSV generado\n",
    "df_index = pd.read_csv('inverted_index.csv')\n",
    "\n",
    "# Mostrar el DataFrame cargado\n",
    "print(df_index.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Word                                              Files\n",
      "0       ﻿the  ['../../data\\\\pg100.txt', '../../data\\\\pg100.t...\n",
      "1    project  ['../../data\\\\pg100.txt', '../../data\\\\pg100.t...\n",
      "2  gutenberg  ['../../data\\\\pg100.txt', '../../data\\\\pg100.t...\n",
      "3      ebook  ['../../data\\\\pg100.txt', '../../data\\\\pg100.t...\n",
      "4    complet  ['../../data\\\\pg100.txt', '../../data\\\\pg100.t...\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T02:44:20.498433Z",
     "start_time": "2024-05-01T02:44:20.480929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search_query(query, df_index):\n",
    "    result = df_index[df_index['Word'] == query]['Files'].tolist()\n",
    "    result = eval(result[0]) if result else []\n",
    "    return set(result)"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 4: Displaying Results\n",
    "- **Output the Results**: Display the documents that match the query criteria. Include functionalities to handle queries that result in no matching documents."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ejemplo de consulta\n",
    "query = \"bug\"\n",
    "\n",
    "# Realizar la búsqueda\n",
    "result = search_query(query, df_index)\n",
    "\n",
    "# Formatear y mostrar los resultados de manera elegante\n",
    "if result:\n",
    "    print(\"Documentos encontrados:\")\n",
    "    formatted_results = [os.path.basename(file_path) for file_path in result]\n",
    "    for file_name in formatted_results:\n",
    "        print(file_name)\n",
    "else:\n",
    "    print(\"No se encontraron documentos relacionados con la consulta.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluation Criteria\n",
    "- **Correctness**: The Boolean search implementation should correctly interpret and process the queries according to the Boolean logic.\n",
    "- **Efficiency**: Consider the efficiency of your search process, especially as the complexity of queries increases.\n",
    "- **User Experience**: Ensure that the interface for inputting queries and viewing results is user-friendly.\n",
    "\n",
    "This exercise will deepen your understanding of how search engines process and respond to user queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
